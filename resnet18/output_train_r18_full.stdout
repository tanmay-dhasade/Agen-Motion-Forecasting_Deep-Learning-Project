Lmod has detected the following error: The following module(s) are unknown:
"cuda10.0/toolkit/10.0.130"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda10.0/toolkit/10.0.130"

Also make sure that all modulefiles written in TCL start with the string
#%Module



Lmod has detected the following error: The following module(s) are unknown:
"cuda10.0/fft/10.0.130"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda10.0/fft/10.0.130"

Also make sure that all modulefiles written in TCL start with the string
#%Module



Lmod has detected the following error: The following module(s) are unknown:
"cudnn/7.4.2"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cudnn/7.4.2"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/var/spool/slurm/d/job31108/slurm_script: line 13: /cm/local/apps/cuda/libs/current/bin/nvidia-smi: No such file or directory
/var/spool/slurm/d/job31108/slurm_script: line 14: conda: command not found
Dataset and L5kit are ready !
/home/trdhasade/ExtractedDataset
{'format_version': 4, 'model_params': {'model_architecture': 'resnet18', 'history_num_frames': 10, 'future_num_frames': 20, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_size': [224, 224], 'pixel_size': [0.5, 0.5], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'train_data_loader': {'key': 'scenes/train.zarr', 'batch_size': 12, 'shuffle': True, 'num_workers': 16}, 'val_data_loader': {'key': 'scenes/validate.zarr', 'batch_size': 12, 'shuffle': False, 'num_workers': 16}, 'train_params': {'checkpoint_every_n_steps': 10000, 'max_num_steps': 50, 'eval_every_n_steps': 10000}}
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
/home/trdhasade/anaconda/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
  0%|          | 0/50 [00:00<?, ?it/s]/home/trdhasade/anaconda/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)
  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
loss: 410.4185485839844 loss(avg): 410.4185485839844:   0%|          | 0/50 [00:22<?, ?it/s]loss: 410.4185485839844 loss(avg): 410.4185485839844:   2%|▏         | 1/50 [00:22<18:45, 22.97s/it]loss: 702.1669311523438 loss(avg): 556.2927398681641:   2%|▏         | 1/50 [00:26<18:45, 22.97s/it]loss: 702.1669311523438 loss(avg): 556.2927398681641:   4%|▍         | 2/50 [00:26<09:23, 11.75s/it]loss: 70.75501251220703 loss(avg): 394.4468307495117:   4%|▍         | 2/50 [00:30<09:23, 11.75s/it]loss: 70.75501251220703 loss(avg): 394.4468307495117:   6%|▌         | 3/50 [00:30<06:24,  8.18s/it]loss: 166.59930419921875 loss(avg): 337.4849491119385:   6%|▌         | 3/50 [00:34<06:24,  8.18s/it]loss: 166.59930419921875 loss(avg): 337.4849491119385:   8%|▊         | 4/50 [00:34<05:01,  6.55s/it]loss: 275.5601806640625 loss(avg): 325.0999954223633:   8%|▊         | 4/50 [00:38<05:01,  6.55s/it] loss: 275.5601806640625 loss(avg): 325.0999954223633:  10%|█         | 5/50 [00:38<04:10,  5.58s/it]loss: 144.80458068847656 loss(avg): 295.05075963338214:  10%|█         | 5/50 [00:42<04:10,  5.58s/it]loss: 144.80458068847656 loss(avg): 295.05075963338214:  12%|█▏        | 6/50 [00:42<03:39,  4.98s/it]loss: 165.36277770996094 loss(avg): 276.5239050728934:  12%|█▏        | 6/50 [00:46<03:39,  4.98s/it] loss: 165.36277770996094 loss(avg): 276.5239050728934:  14%|█▍        | 7/50 [00:46<03:17,  4.60s/it]loss: 133.40628051757812 loss(avg): 258.634202003479:  14%|█▍        | 7/50 [00:50<03:17,  4.60s/it] loss: 133.40628051757812 loss(avg): 258.634202003479:  16%|█▌        | 8/50 [00:50<03:04,  4.40s/it]loss: 149.29103088378906 loss(avg): 246.4849607679579:  16%|█▌        | 8/50 [00:54<03:04,  4.40s/it]loss: 149.29103088378906 loss(avg): 246.4849607679579:  18%|█▊        | 9/50 [00:54<02:51,  4.19s/it]loss: 146.74195861816406 loss(avg): 236.51066055297852:  18%|█▊        | 9/50 [00:57<02:51,  4.19s/it]loss: 146.74195861816406 loss(avg): 236.51066055297852:  20%|██        | 10/50 [00:57<02:40,  4.02s/it]loss: 53.85749435424805 loss(avg): 219.90582726218483:  20%|██        | 10/50 [01:01<02:40,  4.02s/it] loss: 53.85749435424805 loss(avg): 219.90582726218483:  22%|██▏       | 11/50 [01:01<02:34,  3.97s/it]loss: 138.43251037597656 loss(avg): 213.11638418833414:  22%|██▏       | 11/50 [01:05<02:34,  3.97s/it]loss: 138.43251037597656 loss(avg): 213.11638418833414:  24%|██▍       | 12/50 [01:05<02:26,  3.85s/it]loss: 75.66865539550781 loss(avg): 202.54348197350134:  24%|██▍       | 12/50 [01:08<02:26,  3.85s/it] loss: 75.66865539550781 loss(avg): 202.54348197350134:  26%|██▌       | 13/50 [01:08<02:22,  3.86s/it]loss: 80.7116928100586 loss(avg): 193.84121131896973:  26%|██▌       | 13/50 [01:13<02:22,  3.86s/it] loss: 80.7116928100586 loss(avg): 193.84121131896973:  28%|██▊       | 14/50 [01:13<02:20,  3.91s/it]loss: 75.8394546508789 loss(avg): 185.97442754109701:  28%|██▊       | 14/50 [01:16<02:20,  3.91s/it]loss: 75.8394546508789 loss(avg): 185.97442754109701:  30%|███       | 15/50 [01:16<02:16,  3.89s/it]loss: 159.51341247558594 loss(avg): 184.32061409950256:  30%|███       | 15/50 [01:20<02:16,  3.89s/it]loss: 159.51341247558594 loss(avg): 184.32061409950256:  32%|███▏      | 16/50 [01:20<02:12,  3.89s/it]loss: 67.51367950439453 loss(avg): 177.44961794684914:  32%|███▏      | 16/50 [01:24<02:12,  3.89s/it] loss: 67.51367950439453 loss(avg): 177.44961794684914:  34%|███▍      | 17/50 [01:24<02:08,  3.88s/it]loss: 68.73870086669922 loss(avg): 171.41012255350748:  34%|███▍      | 17/50 [01:28<02:08,  3.88s/it]loss: 68.73870086669922 loss(avg): 171.41012255350748:  36%|███▌      | 18/50 [01:28<02:02,  3.83s/it]loss: 63.29018020629883 loss(avg): 165.71959927207544:  36%|███▌      | 18/50 [01:32<02:02,  3.83s/it]loss: 63.29018020629883 loss(avg): 165.71959927207544:  38%|███▊      | 19/50 [01:32<01:57,  3.80s/it]loss: 33.939247131347656 loss(avg): 159.13058166503907:  38%|███▊      | 19/50 [01:35<01:57,  3.80s/it]loss: 33.939247131347656 loss(avg): 159.13058166503907:  40%|████      | 20/50 [01:35<01:54,  3.80s/it]loss: 50.06483459472656 loss(avg): 153.93697466169084:  40%|████      | 20/50 [01:39<01:54,  3.80s/it] loss: 50.06483459472656 loss(avg): 153.93697466169084:  42%|████▏     | 21/50 [01:39<01:50,  3.82s/it]loss: 64.90538787841797 loss(avg): 149.89008435336027:  42%|████▏     | 21/50 [01:43<01:50,  3.82s/it]loss: 64.90538787841797 loss(avg): 149.89008435336027:  44%|████▍     | 22/50 [01:43<01:46,  3.81s/it]loss: 94.56636810302734 loss(avg): 147.48470538595447:  44%|████▍     | 22/50 [01:47<01:46,  3.81s/it]loss: 94.56636810302734 loss(avg): 147.48470538595447:  46%|████▌     | 23/50 [01:47<01:41,  3.76s/it]loss: 53.53962326049805 loss(avg): 143.57032696406046:  46%|████▌     | 23/50 [01:50<01:41,  3.76s/it]loss: 53.53962326049805 loss(avg): 143.57032696406046:  48%|████▊     | 24/50 [01:50<01:37,  3.75s/it]loss: 173.09715270996094 loss(avg): 144.75139999389648:  48%|████▊     | 24/50 [01:54<01:37,  3.75s/it]loss: 173.09715270996094 loss(avg): 144.75139999389648:  50%|█████     | 25/50 [01:54<01:34,  3.77s/it]loss: 195.54151916503906 loss(avg): 146.7048661158635:  50%|█████     | 25/50 [01:58<01:34,  3.77s/it] loss: 195.54151916503906 loss(avg): 146.7048661158635:  52%|█████▏    | 26/50 [01:58<01:29,  3.72s/it]loss: 142.8983612060547 loss(avg): 146.56388445253725:  52%|█████▏    | 26/50 [02:02<01:29,  3.72s/it]loss: 142.8983612060547 loss(avg): 146.56388445253725:  54%|█████▍    | 27/50 [02:02<01:26,  3.75s/it]loss: 161.13076782226562 loss(avg): 147.0841302871704:  54%|█████▍    | 27/50 [02:05<01:26,  3.75s/it]loss: 161.13076782226562 loss(avg): 147.0841302871704:  56%|█████▌    | 28/50 [02:05<01:22,  3.77s/it]loss: 179.190185546875 loss(avg): 148.19123564095332:  56%|█████▌    | 28/50 [02:09<01:22,  3.77s/it] loss: 179.190185546875 loss(avg): 148.19123564095332:  58%|█████▊    | 29/50 [02:09<01:19,  3.77s/it]loss: 129.0077667236328 loss(avg): 147.55178667704266:  58%|█████▊    | 29/50 [02:13<01:19,  3.77s/it]loss: 129.0077667236328 loss(avg): 147.55178667704266:  60%|██████    | 30/50 [02:13<01:15,  3.77s/it]loss: 138.33734130859375 loss(avg): 147.25454650386686:  60%|██████    | 30/50 [02:17<01:15,  3.77s/it]loss: 138.33734130859375 loss(avg): 147.25454650386686:  62%|██████▏   | 31/50 [02:17<01:11,  3.76s/it]loss: 57.56093978881836 loss(avg): 144.4516212940216:  62%|██████▏   | 31/50 [02:20<01:11,  3.76s/it]  loss: 57.56093978881836 loss(avg): 144.4516212940216:  64%|██████▍   | 32/50 [02:20<01:07,  3.75s/it]loss: 77.76943969726562 loss(avg): 142.43094912442294:  64%|██████▍   | 32/50 [02:24<01:07,  3.75s/it]loss: 77.76943969726562 loss(avg): 142.43094912442294:  66%|██████▌   | 33/50 [02:24<01:03,  3.71s/it]loss: 56.266754150390625 loss(avg): 139.89670809577493:  66%|██████▌   | 33/50 [02:28<01:03,  3.71s/it]loss: 56.266754150390625 loss(avg): 139.89670809577493:  68%|██████▊   | 34/50 [02:28<00:59,  3.74s/it]loss: 156.8212127685547 loss(avg): 140.38026537214006:  68%|██████▊   | 34/50 [02:32<00:59,  3.74s/it] loss: 156.8212127685547 loss(avg): 140.38026537214006:  70%|███████   | 35/50 [02:32<00:56,  3.74s/it]loss: 132.11805725097656 loss(avg): 140.15075959099664:  70%|███████   | 35/50 [02:35<00:56,  3.74s/it]loss: 132.11805725097656 loss(avg): 140.15075959099664:  72%|███████▏  | 36/50 [02:35<00:52,  3.74s/it]loss: 72.44405364990234 loss(avg): 138.3208486196157:  72%|███████▏  | 36/50 [02:39<00:52,  3.74s/it]  loss: 72.44405364990234 loss(avg): 138.3208486196157:  74%|███████▍  | 37/50 [02:39<00:49,  3.77s/it]loss: 40.9556884765625 loss(avg): 135.75860756321958:  74%|███████▍  | 37/50 [02:43<00:49,  3.77s/it]loss: 40.9556884765625 loss(avg): 135.75860756321958:  76%|███████▌  | 38/50 [02:43<00:45,  3.83s/it]loss: 53.75691223144531 loss(avg): 133.65599999060998:  76%|███████▌  | 38/50 [02:47<00:45,  3.83s/it]loss: 53.75691223144531 loss(avg): 133.65599999060998:  78%|███████▊  | 39/50 [02:47<00:41,  3.79s/it]loss: 59.70811462402344 loss(avg): 131.80730285644532:  78%|███████▊  | 39/50 [02:51<00:41,  3.79s/it]loss: 59.70811462402344 loss(avg): 131.80730285644532:  80%|████████  | 40/50 [02:51<00:37,  3.79s/it]loss: 111.38135528564453 loss(avg): 131.30910901325504:  80%|████████  | 40/50 [02:54<00:37,  3.79s/it]loss: 111.38135528564453 loss(avg): 131.30910901325504:  82%|████████▏ | 41/50 [02:54<00:33,  3.75s/it]loss: 22.1219482421875 loss(avg): 128.709414709182:  82%|████████▏ | 41/50 [02:58<00:33,  3.75s/it]    loss: 22.1219482421875 loss(avg): 128.709414709182:  84%|████████▍ | 42/50 [02:58<00:30,  3.79s/it]loss: 33.49509048461914 loss(avg): 126.49512809930846:  84%|████████▍ | 42/50 [03:02<00:30,  3.79s/it]loss: 33.49509048461914 loss(avg): 126.49512809930846:  86%|████████▌ | 43/50 [03:02<00:26,  3.78s/it]loss: 43.28327560424805 loss(avg): 124.60394963351163:  86%|████████▌ | 43/50 [03:06<00:26,  3.78s/it]loss: 43.28327560424805 loss(avg): 124.60394963351163:  88%|████████▊ | 44/50 [03:06<00:23,  3.84s/it]loss: 11.707893371582031 loss(avg): 122.09514838324652:  88%|████████▊ | 44/50 [03:10<00:23,  3.84s/it]loss: 11.707893371582031 loss(avg): 122.09514838324652:  90%|█████████ | 45/50 [03:10<00:19,  3.82s/it]loss: 81.97346496582031 loss(avg): 121.22293787417205:  90%|█████████ | 45/50 [03:13<00:19,  3.82s/it] loss: 81.97346496582031 loss(avg): 121.22293787417205:  92%|█████████▏| 46/50 [03:13<00:15,  3.76s/it]loss: 25.665727615356445 loss(avg): 119.18980574100576:  92%|█████████▏| 46/50 [03:17<00:15,  3.76s/it]loss: 25.665727615356445 loss(avg): 119.18980574100576:  94%|█████████▍| 47/50 [03:17<00:11,  3.71s/it]loss: 89.54570770263672 loss(avg): 118.5722203652064:  94%|█████████▍| 47/50 [03:21<00:11,  3.71s/it]  loss: 89.54570770263672 loss(avg): 118.5722203652064:  96%|█████████▌| 48/50 [03:21<00:07,  3.74s/it]loss: 237.12127685546875 loss(avg): 120.99158886500767:  96%|█████████▌| 48/50 [03:24<00:07,  3.74s/it]loss: 237.12127685546875 loss(avg): 120.99158886500767:  98%|█████████▊| 49/50 [03:24<00:03,  3.69s/it]loss: 181.6445770263672 loss(avg): 122.20464862823486:  98%|█████████▊| 49/50 [03:28<00:03,  3.69s/it] loss: 181.6445770263672 loss(avg): 122.20464862823486: 100%|██████████| 50/50 [03:28<00:00,  3.71s/it]loss: 181.6445770263672 loss(avg): 122.20464862823486: 100%|██████████| 50/50 [03:28<00:00,  4.17s/it]
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
look torch.Size([12, 3, 20, 2]) torch.Size([12, 20, 2]) torch.Size([12, 20])
Saved the loss
