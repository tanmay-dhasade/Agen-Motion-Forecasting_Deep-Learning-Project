Lmod has detected the following error: The following module(s) are unknown:
"cuda10.0/toolkit/10.0.130"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda10.0/toolkit/10.0.130"

Also make sure that all modulefiles written in TCL start with the string
#%Module



Lmod has detected the following error: The following module(s) are unknown:
"cuda10.0/fft/10.0.130"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda10.0/fft/10.0.130"

Also make sure that all modulefiles written in TCL start with the string
#%Module



Lmod has detected the following error: The following module(s) are unknown:
"cudnn/7.4.2"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cudnn/7.4.2"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/var/spool/slurm/d/job31098/slurm_script: line 13: /cm/local/apps/cuda/libs/current/bin/nvidia-smi: No such file or directory
/var/spool/slurm/d/job31098/slurm_script: line 14: conda: command not found
Dataset and L5kit are ready !
/home/trdhasade/ExtractedDataset
{'format_version': 4, 'model_params': {'model_architecture': 'vgg16', 'history_num_frames': 0, 'future_num_frames': 50, 'step_time': 0.1, 'render_ego_history': True}, 'raster_params': {'raster_size': [224, 224], 'pixel_size': [0.5, 0.5], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'train_data_loader': {'key': 'scenes/train.zarr', 'batch_size': 12, 'shuffle': True, 'num_workers': 16}, 'val_data_loader': {'key': 'scenes/validate.zarr', 'batch_size': 12, 'shuffle': False, 'num_workers': 16}, 'train_params': {'checkpoint_every_n_steps': 10000, 'max_num_steps': 50, 'eval_every_n_steps': 10000}}
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |
+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+
/home/trdhasade/anaconda/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
  0%|          | 0/50 [00:00<?, ?it/s]/home/trdhasade/anaconda/envs/py37/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)
  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
loss: 177.6927032470703 loss(avg): 177.6927032470703:   0%|          | 0/50 [00:32<?, ?it/s]loss: 177.6927032470703 loss(avg): 177.6927032470703:   2%|▏         | 1/50 [00:32<26:13, 32.10s/it]loss: 12.567887306213379 loss(avg): 95.13029527664185:   2%|▏         | 1/50 [00:48<26:13, 32.10s/it]loss: 12.567887306213379 loss(avg): 95.13029527664185:   4%|▍         | 2/50 [00:48<18:28, 23.09s/it]loss: 452925.0625 loss(avg): 151038.44103018442:   4%|▍         | 2/50 [01:05<18:28, 23.09s/it]      loss: 452925.0625 loss(avg): 151038.44103018442:   6%|▌         | 3/50 [01:05<15:48, 20.19s/it]loss: 142.26351928710938 loss(avg): 113314.3966524601:   6%|▌         | 3/50 [01:22<15:48, 20.19s/it]loss: 142.26351928710938 loss(avg): 113314.3966524601:   8%|▊         | 4/50 [01:22<14:27, 18.85s/it]loss: 66.79515075683594 loss(avg): 90664.87635211945:   8%|▊         | 4/50 [01:39<14:27, 18.85s/it] loss: 66.79515075683594 loss(avg): 90664.87635211945:  10%|█         | 5/50 [01:39<13:33, 18.07s/it]loss: 108.15760803222656 loss(avg): 75572.08989477158:  10%|█         | 5/50 [01:55<13:33, 18.07s/it]loss: 108.15760803222656 loss(avg): 75572.08989477158:  12%|█▏        | 6/50 [01:55<12:55, 17.62s/it]loss: 305.5407409667969 loss(avg): 64819.72572994232:  12%|█▏        | 6/50 [02:12<12:55, 17.62s/it] loss: 305.5407409667969 loss(avg): 64819.72572994232:  14%|█▍        | 7/50 [02:12<12:24, 17.30s/it]loss: 238.8660430908203 loss(avg): 56747.118269085884:  14%|█▍        | 7/50 [02:29<12:24, 17.30s/it]loss: 238.8660430908203 loss(avg): 56747.118269085884:  16%|█▌        | 8/50 [02:29<11:57, 17.08s/it]loss: 41.72202682495117 loss(avg): 50446.51868661245:  16%|█▌        | 8/50 [02:45<11:57, 17.08s/it] loss: 41.72202682495117 loss(avg): 50446.51868661245:  18%|█▊        | 9/50 [02:45<11:34, 16.94s/it]loss: 17.475690841674805 loss(avg): 45403.61438703537:  18%|█▊        | 9/50 [03:02<11:34, 16.94s/it]loss: 17.475690841674805 loss(avg): 45403.61438703537:  20%|██        | 10/50 [03:02<11:16, 16.91s/it]loss: 118.26277160644531 loss(avg): 41286.76424017819:  20%|██        | 10/50 [03:19<11:16, 16.91s/it]loss: 118.26277160644531 loss(avg): 41286.76424017819:  22%|██▏       | 11/50 [03:19<10:56, 16.82s/it]loss: 49.823387145996094 loss(avg): 37850.352502425514:  22%|██▏       | 11/50 [03:35<10:56, 16.82s/it]loss: 49.823387145996094 loss(avg): 37850.352502425514:  24%|██▍       | 12/50 [03:35<10:36, 16.74s/it]loss: 7.872820854187012 loss(avg): 34939.392526920026:  24%|██▍       | 12/50 [03:52<10:36, 16.74s/it] loss: 7.872820854187012 loss(avg): 34939.392526920026:  26%|██▌       | 13/50 [03:52<10:17, 16.70s/it]loss: 115.17906188964844 loss(avg): 32451.948707989282:  26%|██▌       | 13/50 [04:09<10:17, 16.70s/it]loss: 115.17906188964844 loss(avg): 32451.948707989282:  28%|██▊       | 14/50 [04:09<10:01, 16.71s/it]loss: 103.07855987548828 loss(avg): 30295.3573647817:  28%|██▊       | 14/50 [04:25<10:01, 16.71s/it]  loss: 103.07855987548828 loss(avg): 30295.3573647817:  30%|███       | 15/50 [04:25<09:43, 16.66s/it]loss: 339.78436279296875 loss(avg): 28423.134052157402:  30%|███       | 15/50 [04:42<09:43, 16.66s/it]loss: 339.78436279296875 loss(avg): 28423.134052157402:  32%|███▏      | 16/50 [04:42<09:24, 16.60s/it]loss: 52.74652862548828 loss(avg): 26754.28772724376:  32%|███▏      | 16/50 [04:58<09:24, 16.60s/it]  loss: 52.74652862548828 loss(avg): 26754.28772724376:  34%|███▍      | 17/50 [04:58<09:08, 16.62s/it]loss: 49.11448669433594 loss(avg): 25270.66699165768:  34%|███▍      | 17/50 [05:15<09:08, 16.62s/it]loss: 49.11448669433594 loss(avg): 25270.66699165768:  36%|███▌      | 18/50 [05:15<08:52, 16.66s/it]loss: 36.01270294189453 loss(avg): 23942.527292251587:  36%|███▌      | 18/50 [05:32<08:52, 16.66s/it]loss: 36.01270294189453 loss(avg): 23942.527292251587:  38%|███▊      | 19/50 [05:32<08:36, 16.66s/it]loss: 59.237186431884766 loss(avg): 22748.362786960603:  38%|███▊      | 19/50 [05:48<08:36, 16.66s/it]loss: 59.237186431884766 loss(avg): 22748.362786960603:  40%|████      | 20/50 [05:48<08:19, 16.65s/it]loss: 32.70596694946289 loss(avg): 21666.66484315055:  40%|████      | 20/50 [06:05<08:19, 16.65s/it]  loss: 32.70596694946289 loss(avg): 21666.66484315055:  42%|████▏     | 21/50 [06:05<08:02, 16.62s/it]loss: 159.6981658935547 loss(avg): 20689.075448729775:  42%|████▏     | 21/50 [06:21<08:02, 16.62s/it]loss: 159.6981658935547 loss(avg): 20689.075448729775:  44%|████▍     | 22/50 [06:21<07:45, 16.62s/it]loss: 109.0129165649414 loss(avg): 19794.290121244347:  44%|████▍     | 22/50 [06:38<07:45, 16.62s/it]loss: 109.0129165649414 loss(avg): 19794.290121244347:  46%|████▌     | 23/50 [06:38<07:29, 16.63s/it]loss: 5.990725040435791 loss(avg): 18969.77764640252:  46%|████▌     | 23/50 [06:55<07:29, 16.63s/it] loss: 5.990725040435791 loss(avg): 18969.77764640252:  48%|████▊     | 24/50 [06:55<07:12, 16.62s/it]loss: 68.54536437988281 loss(avg): 18213.728355121613:  48%|████▊     | 24/50 [07:11<07:12, 16.62s/it]loss: 68.54536437988281 loss(avg): 18213.728355121613:  50%|█████     | 25/50 [07:11<06:54, 16.60s/it]loss: 25.498132705688477 loss(avg): 17514.181038874845:  50%|█████     | 25/50 [07:28<06:54, 16.60s/it]loss: 25.498132705688477 loss(avg): 17514.181038874845:  52%|█████▏    | 26/50 [07:28<06:37, 16.57s/it]loss: 379.96759033203125 loss(avg): 16879.58054078067:  52%|█████▏    | 26/50 [07:44<06:37, 16.57s/it] loss: 379.96759033203125 loss(avg): 16879.58054078067:  54%|█████▍    | 27/50 [07:44<06:21, 16.61s/it]loss: 57.37970733642578 loss(avg): 16278.787653871945:  54%|█████▍    | 27/50 [08:01<06:21, 16.61s/it]loss: 57.37970733642578 loss(avg): 16278.787653871945:  56%|█████▌    | 28/50 [08:01<06:05, 16.63s/it]loss: 49.16216278076172 loss(avg): 15719.145395558457:  56%|█████▌    | 28/50 [08:18<06:05, 16.63s/it]loss: 49.16216278076172 loss(avg): 15719.145395558457:  58%|█████▊    | 29/50 [08:18<05:48, 16.59s/it]loss: 43.9731559753418 loss(avg): 15196.63965423902:  58%|█████▊    | 29/50 [08:34<05:48, 16.59s/it]  loss: 43.9731559753418 loss(avg): 15196.63965423902:  60%|██████    | 30/50 [08:34<05:31, 16.60s/it]loss: 107.24711608886719 loss(avg): 14709.885056234176:  60%|██████    | 30/50 [08:51<05:31, 16.60s/it]loss: 107.24711608886719 loss(avg): 14709.885056234176:  62%|██████▏   | 31/50 [08:51<05:15, 16.60s/it]loss: 80.60279846191406 loss(avg): 14252.719985678792:  62%|██████▏   | 31/50 [09:08<05:15, 16.60s/it] loss: 80.60279846191406 loss(avg): 14252.719985678792:  64%|██████▍   | 32/50 [09:08<04:59, 16.62s/it]loss: 27.0103816986084 loss(avg): 13821.637876467272:  64%|██████▍   | 32/50 [09:24<04:59, 16.62s/it] loss: 27.0103816986084 loss(avg): 13821.637876467272:  66%|██████▌   | 33/50 [09:24<04:42, 16.60s/it]loss: 162.0859832763672 loss(avg): 13419.88635019695:  66%|██████▌   | 33/50 [09:41<04:42, 16.60s/it]loss: 162.0859832763672 loss(avg): 13419.88635019695:  68%|██████▊   | 34/50 [09:41<04:25, 16.60s/it]loss: 28.143115997314453 loss(avg): 13037.265114934104:  68%|██████▊   | 34/50 [09:57<04:25, 16.60s/it]loss: 28.143115997314453 loss(avg): 13037.265114934104:  70%|███████   | 35/50 [09:57<04:08, 16.59s/it]loss: 160.0021514892578 loss(avg): 12679.563365949525:  70%|███████   | 35/50 [10:14<04:08, 16.59s/it] loss: 160.0021514892578 loss(avg): 12679.563365949525:  72%|███████▏  | 36/50 [10:14<03:51, 16.56s/it]loss: 141.3096160888672 loss(avg): 12340.691642980319:  72%|███████▏  | 36/50 [10:30<03:51, 16.56s/it]loss: 141.3096160888672 loss(avg): 12340.691642980319:  74%|███████▍  | 37/50 [10:30<03:35, 16.58s/it]loss: 76.18095397949219 loss(avg): 12017.941361690822:  74%|███████▍  | 37/50 [10:47<03:35, 16.58s/it]loss: 76.18095397949219 loss(avg): 12017.941361690822:  76%|███████▌  | 38/50 [10:47<03:19, 16.59s/it]loss: 132.5725555419922 loss(avg): 11713.188315379313:  76%|███████▌  | 38/50 [11:04<03:19, 16.59s/it]loss: 132.5725555419922 loss(avg): 11713.188315379313:  78%|███████▊  | 39/50 [11:04<03:02, 16.58s/it]loss: 129.30787658691406 loss(avg): 11423.591304409503:  78%|███████▊  | 39/50 [11:20<03:02, 16.58s/it]loss: 129.30787658691406 loss(avg): 11423.591304409503:  80%|████████  | 40/50 [11:20<02:45, 16.57s/it]loss: 240.54150390625 loss(avg): 11150.833992202108:  80%|████████  | 40/50 [11:37<02:45, 16.57s/it]   loss: 240.54150390625 loss(avg): 11150.833992202108:  82%|████████▏ | 41/50 [11:37<02:29, 16.56s/it]loss: 200.7157440185547 loss(avg): 10890.11689105488:  82%|████████▏ | 41/50 [11:53<02:29, 16.56s/it]loss: 200.7157440185547 loss(avg): 10890.11689105488:  84%|████████▍ | 42/50 [11:53<02:12, 16.60s/it]loss: 115.93997192382812 loss(avg): 10639.5546371216:  84%|████████▍ | 42/50 [12:10<02:12, 16.60s/it]loss: 115.93997192382812 loss(avg): 10639.5546371216:  86%|████████▌ | 43/50 [12:10<01:55, 16.56s/it]loss: 119.61700439453125 loss(avg): 10400.465145468712:  86%|████████▌ | 43/50 [12:26<01:55, 16.56s/it]loss: 119.61700439453125 loss(avg): 10400.465145468712:  88%|████████▊ | 44/50 [12:26<01:39, 16.56s/it]loss: 254.8191680908203 loss(avg): 10175.006345971426:  88%|████████▊ | 44/50 [12:43<01:39, 16.56s/it] loss: 254.8191680908203 loss(avg): 10175.006345971426:  90%|█████████ | 45/50 [12:43<01:22, 16.59s/it]loss: 88.50827026367188 loss(avg): 9955.734648673431:  90%|█████████ | 45/50 [12:59<01:22, 16.59s/it] loss: 88.50827026367188 loss(avg): 9955.734648673431:  92%|█████████▏| 46/50 [12:59<01:06, 16.53s/it]loss: 8.95800495147705 loss(avg): 9744.101103062325:  92%|█████████▏| 46/50 [13:16<01:06, 16.53s/it] loss: 8.95800495147705 loss(avg): 9744.101103062325:  94%|█████████▍| 47/50 [13:16<00:49, 16.54s/it]loss: 20.698286056518555 loss(avg): 9541.53021104137:  94%|█████████▍| 47/50 [13:33<00:49, 16.54s/it]loss: 20.698286056518555 loss(avg): 9541.53021104137:  96%|█████████▌| 48/50 [13:33<00:33, 16.56s/it]loss: 196.96334838867188 loss(avg): 9350.824764864785:  96%|█████████▌| 48/50 [13:49<00:33, 16.56s/it]loss: 196.96334838867188 loss(avg): 9350.824764864785:  98%|█████████▊| 49/50 [13:49<00:16, 16.56s/it]loss: 118.3085708618164 loss(avg): 9166.174440984725:  98%|█████████▊| 49/50 [14:06<00:16, 16.56s/it] loss: 118.3085708618164 loss(avg): 9166.174440984725: 100%|██████████| 50/50 [14:06<00:00, 16.56s/it]loss: 118.3085708618164 loss(avg): 9166.174440984725: 100%|██████████| 50/50 [14:06<00:00, 16.92s/it]
Losses Saved
